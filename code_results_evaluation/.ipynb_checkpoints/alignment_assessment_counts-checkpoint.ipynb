{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb25891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path with autoencoding code\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../code_autoencoding')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "import data_loader as dl\n",
    "import autoencoder\n",
    "import trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3143755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for getting cosine similarity from drug response vectors.\n",
    "def cos_sim(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "def combs_cos_sim(arr):\n",
    "\n",
    "    if len(arr) < 2:\n",
    "        #print(len(arr))\n",
    "        return 1\n",
    "    combs = list(combinations(np.arange(len(arr)), 2))\n",
    "    sims = [cos_sim(arr[c[0]], arr[c[1]]) for c in combs]\n",
    "\n",
    "    return np.mean(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc845a2",
   "metadata": {},
   "source": [
    "#### Read in both the data and meta data for LINCS level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d618292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-b6adbc751b82>:7: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  meta_data = pd.read_csv(meta_data_path, sep = '\\t')\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/shared_landmark_counts_vecs.gctx_n1269922x960.gctx\"\n",
    "lincs_data = dl.load_CMap(data_path)\n",
    "lincs_data = lincs_data.iloc[:, 0:1000000]\n",
    "lincs_vectors = dict(dl.vectorize(lincs_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55b2703b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-7ba989c1cb0a>:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  meta_data = pd.read_csv(meta_data_path, sep = '\\t')\n"
     ]
    }
   ],
   "source": [
    "meta_data_path  = \"../meta_data/GSE92742_Broad_LINCS_inst_info.txt\"\n",
    "meta_data = pd.read_csv(meta_data_path, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f71433",
   "metadata": {},
   "source": [
    "#### Remove meta data for which there is no reponse in the LINCS data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6edb72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data[meta_data['inst_id'].isin(lincs_data.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526113e6",
   "metadata": {},
   "source": [
    "#### Get the vector IDs (inst_id's) corresponding to each pertubation-cell combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96a2cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pert_cell_combs(meta_df, cell_list = False):\n",
    "    \n",
    "    if (cell_list != False):\n",
    "        meta_df = meta_df[meta_df['cell_id'].isin(cell_list)]\n",
    "    \n",
    "    pert_cell_combs = list((zip(meta_df.pert_iname, meta_df.cell_id, meta_df.inst_id)))\n",
    "    \n",
    "    vec_ids = dict()\n",
    "    \n",
    "    for i in range(len(pert_cell_combs)):\n",
    "        pert, cell, inst = pert_cell_combs[i]\n",
    "        \n",
    "        if (pert,cell) in vec_ids:\n",
    "            vec_ids[(pert, cell)].append(inst)\n",
    "        else:\n",
    "            vec_ids[(pert,cell)] = [inst]\n",
    "    \n",
    "    return vec_ids\n",
    "\n",
    "cells = ['MCF7','A375','HT29','PC3','HA1E','YAPC','HELA']\n",
    "pert_cell_vector_dict = get_pert_cell_combs(meta_data, cell_list = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb9af591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145169"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(pert_cell_vector_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ba8a7",
   "metadata": {},
   "source": [
    "#### Compute the mean vector for each pertubation-cell combination. This is the average response for a given cell type and drug in the native space.  Store the mean response to DMSO separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5a478ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vec_from_control(all_vectors, vec_group_dict, cnt_condition = \"DMSO\", batch_cor = True):\n",
    "    \n",
    "    group_mean_vectors = dict()\n",
    "    cnt_mean_vectors = dict()\n",
    "\n",
    "    for k, v in vec_group_dict.items():\n",
    "        \n",
    "        # Get all the vectors within the cell-pert group\n",
    "        group_vectors = {inst_id:(all_vectors[inst_id]) for inst_id in v}\n",
    "\n",
    "        # If we're looking at the control condition for a cell, keep the mean separate. \n",
    "        # Use PCA + k-means clustering to eliminate samples from the smaller batch\n",
    "        if(k[0] == cnt_condition):\n",
    "            \n",
    "            if batch_cor:\n",
    "                # PCA\n",
    "                pca = PCA(n_components=2)\n",
    "                pc_df = pd.DataFrame(data = pca.fit_transform(list(group_vectors.values())), columns = ['PC1', 'PC2'])\n",
    "\n",
    "                # Clustering\n",
    "                kmeans = KMeans(n_clusters=2)\n",
    "                kmeans.fit(pc_df)\n",
    "                pc_df['clusters'] = list(kmeans.labels_)\n",
    "                pc_df['keys'] = group_vectors.keys()\n",
    "\n",
    "                # Visualize for sanity\n",
    "                #plt.scatter(pc_df.PC1, pc_df.PC2, c = pc_df.clusters)\n",
    "                #plt.show()\n",
    "\n",
    "                # Drop samples from the smaller cluster\n",
    "                largest_cluster = max(set(pc_df.clusters), key = list(pc_df.clusters).count)\n",
    "                cnt_keep = pc_df[pc_df.clusters == largest_cluster]['keys']\n",
    "                cnt_mean_vectors[k[1]] = np.mean([group_vectors[keep] for keep in cnt_keep], axis = 0)\n",
    "            else:\n",
    "                cnt_mean_vectors[k[1]] = np.mean(list(group_vectors.values()), axis = 0)\n",
    "                \n",
    "        else:\n",
    "            # Compute the mean vector for each group\n",
    "            group_mean_vectors[k] = np.mean(list(group_vectors.values()), axis = 0)\n",
    "                \n",
    "\n",
    "    \n",
    "    # Stubtract the mean control vector from everything for each group. Drop cnt vectors and those without a control\n",
    "    cnt_normed_mean_vectors = group_mean_vectors.copy()\n",
    "    \n",
    "    for k, v in group_mean_vectors.items():\n",
    "        \n",
    "        if k[1] == cnt_condition:\n",
    "            cnt_normed_mean_vectors.pop(k)\n",
    "        elif k[1] in cnt_mean_vectors:\n",
    "            cnt_normed_mean_vectors[k] = v - cnt_mean_vectors[k[1]]\n",
    "        else:\n",
    "            cnt_normed_mean_vectors.pop(k)\n",
    "    \n",
    "    return cnt_normed_mean_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e365176",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vectors_native = get_mean_vec_from_control(lincs_vectors, pert_cell_vector_dict, cnt_condition = \"DMSO\", batch_cor = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ea2f3",
   "metadata": {},
   "source": [
    "#### For each perturbation, get the cosine similarity between the mean responses for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eea178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_cos_sims(all_vectors, meta_df, grp_id = 'pert_iname', ind_id = 'cell_id'):\n",
    "    \n",
    "    # Remove any meta data entries tha don't have corresponding vectors\n",
    "    grps, inds = (zip(*mean_vectors_native.keys()))\n",
    "    meta_df =  meta_df.loc[(meta_df[grp_id].isin(grps)) & (meta_df[ind_id].isin(inds))]\n",
    "    \n",
    "    grp_cos_sims = dict()\n",
    "\n",
    "    for grp in set(meta_df[grp_id]):\n",
    "\n",
    "        keys = [(grp, ind) for ind in set(meta_df[meta_df[grp_id] == grp][ind_id])]\n",
    "\n",
    "        grp_vectors = [all_vectors[(grp, ind)] for (grp, ind) in keys]\n",
    "\n",
    "        grp_cos_sims[grp] = combs_cos_sim(grp_vectors)\n",
    "    \n",
    "    return grp_cos_sims\n",
    "\n",
    "native_cos_sims = get_group_cos_sims(mean_vectors_native, meta_data, grp_id = 'pert_iname', ind_id = 'cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(native_cos_sims.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3678c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_rep(native_vectors, model_path):\n",
    "    \n",
    "    vectors_torch = dl.TorchVectors(list(native_vectors.items()))\n",
    "    val_loader = DataLoader(vectors_torch, batch_size=1, pin_memory=True, shuffle=False)\n",
    "\n",
    "    # Retrieve the architecture of the model\n",
    "    params = torch.load(model_path)\n",
    "    latent_size, input_size = params['state_dict']['net.0.weight'].shape\n",
    "    weights_encode = torch.nn.Parameter(params['state_dict']['net.0.weight'])\n",
    "    \n",
    "    # Initialize the encoding layer, apply weights\n",
    "    to_latent_nn = nn.Linear(input_size, latent_size, bias=False)\n",
    "    to_latent_nn.weight = weights_encode\n",
    "    to_latent_nn.eval()\n",
    "    to_latent_nn.cuda()\n",
    "    \n",
    "    output = dict()\n",
    "\n",
    "    for idx, batch in enumerate(val_loader):\n",
    "        \n",
    "        key, vals = batch[0][0], batch[1]\n",
    "        inputs = Variable(vals).cuda()\n",
    "        with torch.no_grad():\n",
    "            output[key] = to_latent_nn(inputs)\n",
    "    to_latent_nn.cpu()\n",
    "\n",
    "    latent_vectors = dict()\n",
    "\n",
    "    for key, vals in output.items():\n",
    "        latent_vectors[key] = vals.cpu().numpy()[0]\n",
    "    \n",
    "    return latent_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3683d10",
   "metadata": {},
   "source": [
    "#### Now map to the latent space for a model before checking the improvement in alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd7fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = get_latent_rep(lincs_vectors, \"../trained_model_parameters/5.93e-06_counts150epoch_leakyReLu_960_1024_model_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43298ef8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_vectors_latent = get_mean_vec_from_control(latent_vectors, pert_cell_vector_dict, cnt_condition = \"DMSO\", batch_cor = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_cos_sims = get_group_cos_sims(mean_vectors_latent, meta_data, grp_id = 'pert_iname', ind_id = 'cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55928555",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(native_cos_sims.values(), alpha = 0.5)\n",
    "plt.hist(latent_cos_sims.values(), alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b468f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(native_cos_sims.values(), latent_cos_sims.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.96708155, -0.77037339, -0.57366524, -0.37695708, -0.18024893,\n",
    "         0.01645923,  0.21316738,  0.40987554,  0.60658369,  0.80329185,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9038479",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_keys = []\n",
    "for k, v in latent_cos_sims.items():\n",
    "    if (np.abs(v) < 0.5):\n",
    "        bad_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12cf06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
