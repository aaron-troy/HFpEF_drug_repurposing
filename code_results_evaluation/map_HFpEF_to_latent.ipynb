{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path with autoencoding code\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../code_autoencoding')\n",
    "\n",
    "#Torch and utilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "import data_loader as dl\n",
    "import autoencoder\n",
    "import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/HF_LM_genes_counts.csv\"\n",
    "pEF_df = pd.read_csv(data_path)\n",
    "\n",
    "vec_keys = [k for k in pEF_df.columns if re.search('X\\d{3,5}', k)]\n",
    "\n",
    "pEF_vectors = dl.vectorize(pEF_df.iloc[:, pEF_df.columns.isin(vec_keys)], scale_min_max=True, scale_log2_1=False)\n",
    "\n",
    "#pEF_vectors = {k : np.array(pEF_df[k]) for k in vec_keys}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pEF_vectors_torch = dl.TorchVectors(pEF_vectors)\n",
    "eval_loader = DataLoader(pEF_vectors_torch, batch_size=1, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008806358604013677\n"
     ]
    }
   ],
   "source": [
    "#model_param_files = glob.glob(\"trained_model_params/modZ_input/*.pth\")\n",
    "model_param_files = ['../trained_model_parameters/3.46e-06_counts_leakyReLu_960_1100_model_best.pth']\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for f in model_param_files:\n",
    "    \n",
    "    # Load parameters from training\n",
    "    params = torch.load(f)\n",
    "    \n",
    "    # Get the dimensions of the first layer and the weights\n",
    "    latent_size, input_size = params['state_dict']['net.0.weight'].shape\n",
    "    \n",
    "    AE = autoencoder.Autoencoder(input_size,latent_size)\n",
    "    AE.set_weights(params)\n",
    "    #AE.double()\n",
    "    AE.cuda()\n",
    "    \n",
    "    loss = trainer.val_step(AE, eval_loader, prt = False)\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
