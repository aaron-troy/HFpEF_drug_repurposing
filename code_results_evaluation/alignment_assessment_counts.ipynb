{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd52eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path with autoencoding code\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../code_autoencoding')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "import data_loader as dl\n",
    "import autoencoder\n",
    "import trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3f5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for getting cosine similarity from drug response vectors.\n",
    "\n",
    "# Function: compute and return the cosine similarity between two arrays\n",
    "def cos_sim(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "# Function: computes and returns the cosine simiarities between all combinations of the vectors in the passed array. \n",
    "# Set flag mean = True to return the mean cosine simarity rather than an array of all similarities \n",
    "def combs_cos_sim(arr, mean = True):\n",
    "\n",
    "    if len(arr) < 2:\n",
    "        #print(len(arr))\n",
    "        return 1\n",
    "    combs = list(combinations(np.arange(len(arr)), 2))\n",
    "    sims = [cos_sim(arr[c[0]], arr[c[1]]) for c in combs]\n",
    "    \n",
    "    if mean: \n",
    "        return np.mean(sims)\n",
    "    else:\n",
    "        return sims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8fadc",
   "metadata": {},
   "source": [
    "#### Read in both the data and meta data for LINCS level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3e82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/shared_landmark_counts_vecs.gctx_n1269922x960.gctx\"\n",
    "lincs_data = dl.load_CMap(data_path)\n",
    "#lincs_data = lincs_data.iloc[:,0:50000]\n",
    "lincs_data = lincs_data.iloc[:, np.random.choice(np.arange(lincs_data.shape[1]), size=500000, replace=False)]\n",
    "lincs_vectors = dict(dl.vectorize(lincs_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4354701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-aa6d47874146>:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  meta_data = pd.read_csv(meta_data_path, sep = '\\t')\n"
     ]
    }
   ],
   "source": [
    "meta_data_path  = \"../meta_data/GSE92742_Broad_LINCS_inst_info.txt\"\n",
    "meta_data = pd.read_csv(meta_data_path, sep = '\\t')\n",
    "\n",
    "meta_data['pert_time'] = meta_data['pert_time'].apply(str)\n",
    "meta_data['pert_dose'] = meta_data['pert_dose'].apply(str)\n",
    "meta_data['appPert_id'] = meta_data[['pert_iname', 'pert_dose', 'pert_time']].agg('_'.join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074766f",
   "metadata": {},
   "source": [
    "#### Remove meta data for which there is no reponse in the LINCS data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fea026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data[meta_data['inst_id'].isin(lincs_data.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc39ad",
   "metadata": {},
   "source": [
    "#### Get the vector IDs (inst_id's) corresponding to each pertubation-cell combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134b1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pert_cell_combs(meta_df, pert_ident = 'pert_iname', cell_list = False):\n",
    "    \n",
    "    # Strip the meta data to include only the cell types of interest, if desired. \n",
    "    if (cell_list != False):\n",
    "        meta_df = meta_df[meta_df['cell_id'].isin(cell_list)]\n",
    "    \n",
    "    # Get a list of perturbation, cell, and instance combinations \n",
    "    pert_cell_combs = list((zip(meta_df[pert_ident], meta_df.cell_id, meta_df.inst_id)))\n",
    "    \n",
    "    # Construct a dict that maps a perturbation and cell combination to a list of associated vector IDs\n",
    "    vec_ids = dict()\n",
    "    \n",
    "    for i in range(len(pert_cell_combs)):\n",
    "        pert, cell, inst = pert_cell_combs[i]\n",
    "        \n",
    "        if (pert,cell) in vec_ids:\n",
    "            vec_ids[(pert, cell)].append(inst)\n",
    "        else:\n",
    "            vec_ids[(pert,cell)] = [inst]\n",
    "    \n",
    "    return vec_ids\n",
    "\n",
    "cells = ['MCF7','A375','HT29','PC3','HA1E','YAPC','HELA']\n",
    "pert_cell_vector_dict = get_pert_cell_combs(meta_data, pert_ident = 'pert_iname', cell_list = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e5f18",
   "metadata": {},
   "source": [
    "#### Compute the mean vector for each pertubation-cell combination. This is the average response for a given cell type and drug in the native space.  Store the mean response to DMSO separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff626912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vec_from_control(all_vectors, vec_group_dict, cnt_condition = \"DMSO\", batch_cor = True):\n",
    "    \n",
    "    group_mean_vectors = dict()\n",
    "    cnt_mean_vectors = dict()\n",
    "\n",
    "    for k, v in vec_group_dict.items():\n",
    "        \n",
    "        # Get all the vectors within the cell-pert group\n",
    "        group_vectors = {inst_id:(all_vectors[inst_id]) for inst_id in v}\n",
    "\n",
    "        # If we're looking at the control condition for a cell, keep the mean separate. \n",
    "        # Use PCA + k-means clustering to eliminate samples from the smaller batch\n",
    "        if(cnt_condition in k[0]):\n",
    "            \n",
    "            # Often the control response will contain more than one cluster due to batch effects. Using only the largest cluster\n",
    "            # for normalization cleans things up. \n",
    "            if batch_cor and len(group_vectors) > 1:\n",
    "                # PCA\n",
    "                pca = PCA(n_components=2)\n",
    "\n",
    "                pc_df = pd.DataFrame(data = pca.fit_transform(list(group_vectors.values())), columns = ['PC1', 'PC2'])\n",
    "\n",
    "                # Clustering\n",
    "                kmeans = KMeans(n_clusters=2)\n",
    "                kmeans.fit(pc_df)\n",
    "                pc_df['clusters'] = list(kmeans.labels_)\n",
    "                pc_df['keys'] = group_vectors.keys()\n",
    "\n",
    "                # Visualize for sanity\n",
    "                #plt.scatter(pc_df.PC1, pc_df.PC2, c = pc_df.clusters)\n",
    "                #plt.show()\n",
    "\n",
    "                # Drop samples from the smaller cluster\n",
    "                largest_cluster = max(set(pc_df.clusters), key = list(pc_df.clusters).count)\n",
    "                cnt_keep = pc_df[pc_df.clusters == largest_cluster]['keys']              \n",
    "\n",
    "                cnt_mean_vectors[k[1]] = np.mean([group_vectors[keep] for keep in cnt_keep], axis = 0)\n",
    "                    \n",
    "            else:\n",
    "                cnt_mean_vectors[k[1]] = np.mean(list(group_vectors.values()), axis = 0)\n",
    "                \n",
    "        else:\n",
    "            # Compute the mean vector for each group\n",
    "            group_mean_vectors[k] = np.mean(list(group_vectors.values()), axis = 0)\n",
    "                \n",
    "    \n",
    "    # Stubtract the mean control vector from everything for each group. Drop cnt vectors and those without a control\n",
    "    cnt_normed_mean_vectors = group_mean_vectors.copy()\n",
    "    \n",
    "    for k, v in group_mean_vectors.items():\n",
    "        \n",
    "        if k[1] == cnt_condition:\n",
    "            cnt_normed_mean_vectors.pop(k)\n",
    "        elif k[1] in cnt_mean_vectors:\n",
    "            cnt_normed_mean_vectors[k] = v - cnt_mean_vectors[k[1]]\n",
    "        else:\n",
    "            cnt_normed_mean_vectors.pop(k)\n",
    "    \n",
    "    return cnt_normed_mean_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b2bc659",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vectors_native = get_mean_vec_from_control(lincs_vectors, pert_cell_vector_dict, cnt_condition = \"DMSO\", batch_cor = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae8744",
   "metadata": {},
   "source": [
    "#### For each perturbation, get the cosine similarity between the mean responses for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c0a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_cos_sims(all_vectors, meta_df, grp_id = 'pert_iname', ind_id = 'cell_id', mean = True):\n",
    "    \n",
    "    # Remove any meta data entries tha don't have corresponding vectors\n",
    "    grps, inds = (zip(*mean_vectors_native.keys()))\n",
    "    meta_df =  meta_df.loc[(meta_df[grp_id].isin(grps)) & (meta_df[ind_id].isin(inds))]\n",
    "    \n",
    "    grp_cos_sims = dict()\n",
    "\n",
    "    for grp in set(meta_df[grp_id]):\n",
    "\n",
    "        keys = [(grp, ind) for ind in set(meta_df[meta_df[grp_id] == grp][ind_id])]\n",
    "\n",
    "        grp_vectors = [all_vectors[(grp, ind)] for (grp, ind) in keys]\n",
    "        \n",
    "        if (len(grp_vectors) > 1):\n",
    "            grp_cos_sims[grp] = combs_cos_sim(grp_vectors, mean = mean)\n",
    "    \n",
    "    return grp_cos_sims\n",
    "\n",
    "native_cos_sims = get_group_cos_sims(mean_vectors_native, meta_data, grp_id = 'pert_iname', ind_id = 'cell_id', mean = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be91af58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4109.,  15717.,  36997.,  74302., 129797., 148285., 109392.,\n",
       "         70002.,  37953.,  30296.]),\n",
       " array([-0.9627282 , -0.76827145, -0.57381469, -0.3793579 , -0.18490115,\n",
       "         0.00955561,  0.20401236,  0.39846912,  0.59292591,  0.78738266,\n",
       "         0.98183942]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXu0lEQVR4nO3df7BfdZ3f8edrk4K6O0iQlMWEMbGm2khbxQymdWbXFQsBdwydog3tluimpq643ba7o2GdKR1dptjtLF2mypZKlmAtyGbXIS3QNAKO0xmDxF/8XMwVVJICyRLAbh1R9N0/vp9rj5fvyb2533u/NyTPx8x37jnv8znnvO+5P173nO/5fm+qCkmShvm5hW5AknT0MiQkSb0MCUlSL0NCktTLkJAk9Vq80A3MtVNPPbVWrFix0G1I0ovKV77ylb+oqqVT68dcSKxYsYI9e/YsdBuS9KKS5DvD6l5ukiT1MiQkSb0MCUlSL0NCktTLkJAk9TIkJEm9DAlJUi9DQpLUy5CQJPU65l5xLR2tVmy5dcH2/e0r37Fg+9aLm2cSkqRehoQkqZchIUnqZUhIknoZEpKkXoaEJKmXISFJ6jVtSCTZmuRAkvuHLPvtJJXk1DafJFcnmUhyb5KzOmM3JtnbHhs79Tclua+tc3WStPopSXa18buSLJmbT1mSNFMzOZO4Hlg3tZjkDOBc4Lud8vnAqvbYDFzTxp4CXA68GTgbuLzzS/8a4H2d9Sb3tQW4o6pWAXe0eUnSGE0bElX1ReDQkEVXAR8CqlNbD9xQA7uBk5OcDpwH7KqqQ1X1NLALWNeWnVRVu6uqgBuACzvb2tamt3XqkqQxmdVzEknWA/ur6htTFi0DHuvM72u1w9X3DakDnFZVj7fpJ4DTDtPP5iR7kuw5ePDgkX46kqQeRxwSSV4G/C7wr+e+neHaWUYdZvm1VbWmqtYsXbp0XG1J0jFvNmcSfw1YCXwjybeB5cBXk/wisB84ozN2easdrr58SB3gyXY5ivbxwCx6lSSN4IhDoqruq6q/WlUrqmoFg0tEZ1XVE8AO4JJ2l9Na4Nl2yWgncG6SJe0J63OBnW3Z95KsbXc1XQLc0na1A5i8C2pjpy5JGpOZ3AJ7I/Al4LVJ9iXZdJjhtwGPABPAfwY+AFBVh4CPAfe0x0dbjTbmU22dbwG3t/qVwN9Lshd4e5uXJI3RtP9Poqounmb5is50AZf2jNsKbB1S3wOcOaT+FHDOdP1JkuaPr7iWJPUyJCRJvQwJSVIvQ0KS1MuQkCT1MiQkSb0MCUlSL0NCktTLkJAk9Zr2FdfSsWbFllsXugXpRcMzCUlSL0NCktTLkJAk9TIkJEm9DAlJUi9DQpLUy5CQJPUyJCRJvQwJSVKvaUMiydYkB5Lc36n9fpI/T3Jvks8lObmz7LIkE0keTnJep76u1SaSbOnUVya5u9U/m+SEVj+xzU+05Svm6pOWJM3MTM4krgfWTantAs6sqr8FfBO4DCDJamAD8Pq2zieTLEqyCPgEcD6wGri4jQX4OHBVVb0GeBrY1OqbgKdb/ao2TpI0RtOGRFV9ETg0pfY/q+r5NrsbWN6m1wM3VdVzVfUoMAGc3R4TVfVIVf0QuAlYnyTA24Dtbf1twIWdbW1r09uBc9p4SdKYzMVzEr8O3N6mlwGPdZbta7W++iuAZzqBM1n/mW215c+28S+QZHOSPUn2HDx4cORPSJI0MFJIJPkI8DzwmblpZ3aq6tqqWlNVa5YuXbqQrUjSMWXWbxWe5D3ArwLnVFW18n7gjM6w5a1GT/0p4OQki9vZQnf85Lb2JVkMvLyNlySNyazOJJKsAz4EvLOqvt9ZtAPY0O5MWgmsAr4M3AOsancyncDgye0dLVzuAi5q628Ebulsa2Obvgi4sxNGkqQxmPZMIsmNwFuBU5PsAy5ncDfTicCu9lzy7qp6f1U9kORm4EEGl6Euraoft+18ENgJLAK2VtUDbRcfBm5K8nvA14DrWv064NNJJhg8cb5hDj5fSdIRmDYkquriIeXrhtQmx18BXDGkfhtw25D6Iwzufppa/wHwrun6kyTNH19xLUnqZUhIknoZEpKkXoaEJKmXISFJ6mVISJJ6GRKSpF6GhCSplyEhSeo16zf4k/TisWLLrQuy329f+Y4F2a/mjmcSkqRehoQkqZchIUnqZUhIknoZEpKkXoaEJKmXISFJ6mVISJJ6GRKSpF7ThkSSrUkOJLm/Uzslya4ke9vHJa2eJFcnmUhyb5KzOutsbOP3JtnYqb8pyX1tnauT5HD7kCSNz0zOJK4H1k2pbQHuqKpVwB1tHuB8YFV7bAaugcEvfOBy4M3A2cDlnV/61wDv66y3bpp9SJLGZNqQqKovAoemlNcD29r0NuDCTv2GGtgNnJzkdOA8YFdVHaqqp4FdwLq27KSq2l1VBdwwZVvD9iFJGpPZPidxWlU93qafAE5r08uAxzrj9rXa4er7htQPt48XSLI5yZ4kew4ePDiLT0eSNMzIT1y3M4Cag15mvY+quraq1lTVmqVLl85nK5J0XJltSDzZLhXRPh5o9f3AGZ1xy1vtcPXlQ+qH24ckaUxmGxI7gMk7lDYCt3Tql7S7nNYCz7ZLRjuBc5MsaU9YnwvsbMu+l2Rtu6vpkinbGrYPSdKYTPtPh5LcCLwVODXJPgZ3KV0J3JxkE/Ad4N1t+G3ABcAE8H3gvQBVdSjJx4B72riPVtXkk+EfYHAH1UuB29uDw+xDkjQm04ZEVV3cs+icIWMLuLRnO1uBrUPqe4Azh9SfGrYPSdL4+IprSVIvQ0KS1MuQkCT1MiQkSb0MCUlSL0NCktTLkJAk9TIkJEm9DAlJUi9DQpLUy5CQJPUyJCRJvQwJSVIvQ0KS1MuQkCT1MiQkSb0MCUlSL0NCktTLkJAk9RopJJL8yyQPJLk/yY1JXpJkZZK7k0wk+WySE9rYE9v8RFu+orOdy1r94STnderrWm0iyZZRepUkHblZh0SSZcA/B9ZU1ZnAImAD8HHgqqp6DfA0sKmtsgl4utWvauNIsrqt93pgHfDJJIuSLAI+AZwPrAYubmMlSWMy6uWmxcBLkywGXgY8DrwN2N6WbwMubNPr2zxt+TlJ0uo3VdVzVfUoMAGc3R4TVfVIVf0QuKmNlSSNyaxDoqr2A/8e+C6DcHgW+ArwTFU934btA5a16WXAY23d59v4V3TrU9bpq79Aks1J9iTZc/Dgwdl+SpKkKUa53LSEwV/2K4FXAj/P4HLR2FXVtVW1pqrWLF26dCFakKRj0iiXm94OPFpVB6vqR8CfAW8BTm6XnwCWA/vb9H7gDIC2/OXAU936lHX66pKkMRklJL4LrE3ysvbcwjnAg8BdwEVtzEbglja9o83Tlt9ZVdXqG9rdTyuBVcCXgXuAVe1uqRMYPLm9Y4R+JUlHaPH0Q4arqruTbAe+CjwPfA24FrgVuCnJ77XadW2V64BPJ5kADjH4pU9VPZDkZgYB8zxwaVX9GCDJB4GdDO6c2lpVD8y2X0nSkZt1SABU1eXA5VPKjzC4M2nq2B8A7+rZzhXAFUPqtwG3jdKjJGn2fMW1JKmXISFJ6jXS5SZptlZsuXWhW5A0A55JSJJ6GRKSpF6GhCSplyEhSeplSEiSenl3k6R5s5B3sX37yncs2L6PJZ5JSJJ6GRKSpF6GhCSplyEhSeplSEiSehkSkqRehoQkqZchIUnqZUhIknoZEpKkXiOFRJKTk2xP8udJHkryd5KckmRXkr3t45I2NkmuTjKR5N4kZ3W2s7GN35tkY6f+piT3tXWuTpJR+pUkHZlRzyT+EPgfVfU64G8DDwFbgDuqahVwR5sHOB9Y1R6bgWsAkpwCXA68GTgbuHwyWNqY93XWWzdiv5KkIzDrkEjycuCXgOsAquqHVfUMsB7Y1oZtAy5s0+uBG2pgN3ByktOB84BdVXWoqp4GdgHr2rKTqmp3VRVwQ2dbkqQxGOVMYiVwEPjjJF9L8qkkPw+cVlWPtzFPAKe16WXAY53197Xa4er7htRfIMnmJHuS7Dl48OAIn5IkqWuUkFgMnAVcU1VvBP4v///SEgDtDKBG2MeMVNW1VbWmqtYsXbp0vncnSceNUUJiH7Cvqu5u89sZhMaT7VIR7eOBtnw/cEZn/eWtdrj68iF1SdKYzDokquoJ4LEkr22lc4AHgR3A5B1KG4Fb2vQO4JJ2l9Na4Nl2WWoncG6SJe0J63OBnW3Z95KsbXc1XdLZliRpDEb9z3S/CXwmyQnAI8B7GQTPzUk2Ad8B3t3G3gZcAEwA329jqapDST4G3NPGfbSqDrXpDwDXAy8Fbm8PSdKYjBQSVfV1YM2QRecMGVvApT3b2QpsHVLfA5w5So+SpNnzFdeSpF6GhCSplyEhSeplSEiSehkSkqRehoQkqZchIUnqZUhIknoZEpKkXoaEJKmXISFJ6mVISJJ6GRKSpF6GhCSplyEhSeplSEiSehkSkqRehoQkqZchIUnqNXJIJFmU5GtJ/nubX5nk7iQTST6b5IRWP7HNT7TlKzrbuKzVH05yXqe+rtUmkmwZtVdJ0pGZizOJ3wIe6sx/HLiqql4DPA1savVNwNOtflUbR5LVwAbg9cA64JMteBYBnwDOB1YDF7exkqQxGSkkkiwH3gF8qs0HeBuwvQ3ZBlzYpte3edryc9r49cBNVfVcVT0KTABnt8dEVT1SVT8EbmpjJUljMuqZxH8APgT8pM2/Animqp5v8/uAZW16GfAYQFv+bBv/0/qUdfrqL5Bkc5I9SfYcPHhwxE9JkjRp1iGR5FeBA1X1lTnsZ1aq6tqqWlNVa5YuXbrQ7UjSMWPxCOu+BXhnkguAlwAnAX8InJxkcTtbWA7sb+P3A2cA+5IsBl4OPNWpT+qu01eXJI3BrEOiqi4DLgNI8lbgd6rqHyf5E+AiBs8hbARuaavsaPNfasvvrKpKsgP4r0n+AHglsAr4MhBgVZKVDMJhA/CPZtuvpOPLii23Lsh+v33lOxZkv/NllDOJPh8Gbkrye8DXgOta/Trg00kmgEMMfulTVQ8kuRl4EHgeuLSqfgyQ5IPATmARsLWqHpiHfo9rC/WDJOnFYU5Coqq+AHyhTT/C4M6kqWN+ALyrZ/0rgCuG1G8DbpuLHiVJR85XXEuSehkSkqRehoQkqZchIUnqZUhIknoZEpKkXoaEJKnXfLyYTpKOWwv5AtX5eLW3ZxKSpF6GhCSplyEhSeplSEiSehkSkqRehoQkqZchIUnqZUhIknoZEpKkXoaEJKmXISFJ6jXrkEhyRpK7kjyY5IEkv9XqpyTZlWRv+7ik1ZPk6iQTSe5NclZnWxvb+L1JNnbqb0pyX1vn6iQZ5ZOVJB2ZUc4kngd+u6pWA2uBS5OsBrYAd1TVKuCONg9wPrCqPTYD18AgVIDLgTcDZwOXTwZLG/O+znrrRuhXknSEZh0SVfV4VX21Tf8f4CFgGbAe2NaGbQMubNPrgRtqYDdwcpLTgfOAXVV1qKqeBnYB69qyk6pqd1UVcENnW5KkMZiT5ySSrADeCNwNnFZVj7dFTwCntellwGOd1fa12uHq+4bUh+1/c5I9SfYcPHhwtE9GkvRTI4dEkl8A/hT4F1X1ve6ydgZQo+5jOlV1bVWtqao1S5cune/dSdJxY6SQSPJXGATEZ6rqz1r5yXapiPbxQKvvB87orL681Q5XXz6kLkkak1HubgpwHfBQVf1BZ9EOYPIOpY3ALZ36Je0up7XAs+2y1E7g3CRL2hPW5wI727LvJVnb9nVJZ1uSpDEY5d+XvgX4J8B9Sb7ear8LXAncnGQT8B3g3W3ZbcAFwATwfeC9AFV1KMnHgHvauI9W1aE2/QHgeuClwO3tIUkak1mHRFX9L6DvdQvnDBlfwKU929oKbB1S3wOcOdseJUmjGeVMQnNoIf95uiT18W05JEm9DAlJUi9DQpLUy5CQJPUyJCRJvQwJSVIvQ0KS1MuQkCT1MiQkSb0MCUlSL0NCktTLkJAk9TIkJEm9DAlJUi9DQpLUy/8n0eH/dJCkn+WZhCSplyEhSep11IdEknVJHk4ykWTLQvcjSceTozokkiwCPgGcD6wGLk6yemG7kqTjx1EdEsDZwERVPVJVPwRuAtYvcE+SdNw42u9uWgY81pnfB7x56qAkm4HNbfYvkzw8zXZPBf5iTjqce0dzb3B092dvs2Nvs3PU9ZaP/3RyNr29aljxaA+JGamqa4FrZzo+yZ6qWjOPLc3a0dwbHN392dvs2NvsHC+9He2Xm/YDZ3Tml7eaJGkMjvaQuAdYlWRlkhOADcCOBe5Jko4bR/Xlpqp6PskHgZ3AImBrVT0wB5ue8aWpBXA09wZHd3/2Njv2NjvHRW+pqrnaliTpGHO0X26SJC0gQ0KS1OuYDYkk70ryQJKfJOm9FazvbT/ak+V3t/pn2xPnc9XbKUl2JdnbPi4ZMuZXkny98/hBkgvbsuuTPNpZ9oZx9tbG/biz/x2d+rwdt5n2l+QNSb7Uvv73JvmHnWVzeuyme9uYJCe24zDRjsuKzrLLWv3hJOeN0scse/tXSR5sx+iOJK/qLBv69R1zf+9JcrDTxz/tLNvYvgf2Jtm4AL1d1enrm0me6Sybt2OXZGuSA0nu71meJFe3vu9NclZn2eyOWVUdkw/gbwCvBb4ArOkZswj4FvBq4ATgG8DqtuxmYEOb/iPgN+awt38HbGnTW4CPTzP+FOAQ8LI2fz1w0Twdtxn1BvxlT33ejttM+wP+OrCqTb8SeBw4ea6P3eG+fzpjPgD8UZveAHy2Ta9u408EVrbtLJrD4zST3n6l8z31G5O9He7rO+b+3gP8xyHrngI80j4uadNLxtnblPG/yeCmmnk/dsAvAWcB9/csvwC4HQiwFrh71GN2zJ5JVNVDVTXdK6+Hvu1HkgBvA7a3cduAC+ewvfVtmzPd9kXA7VX1/Tnsoc+R9vZTYzhuMIP+quqbVbW3Tf9v4ACwdI77gJm9bUy33+3AOe04rQduqqrnqupRYKJtb2y9VdVdne+p3QxehzQuo7zlznnArqo6VFVPA7uAdQvY28XAjXO4/15V9UUGfzD2WQ/cUAO7gZOTnM4Ix+yYDYkZGva2H8uAVwDPVNXzU+pz5bSqerxNPwGcNs34Dbzwm/CKdjp5VZITF6C3lyTZk2T35GUw5v+4HUl/ACQ5m8Ffg9/qlOfq2PV9/wwd047LswyO00zWHcWRbn8Tg79AJw37+s6lmfb3D9rXanuSyRfWHjXHrl2iWwnc2SnP97E7nL7eZ33MjurXSUwnyeeBXxyy6CNVdcu4++k6XG/dmaqqJL33Ibe/Av4mg9eKTLqMwS/IExjcD/1h4KNj7u1VVbU/yauBO5Pcx+AX4Mjm+Nh9GthYVT9p5ZGO3bEoya8Ba4Bf7pRf8PWtqm8N38K8+W/AjVX1XJJ/xuCM7G1j7mE6G4DtVfXjTu1oOHZz5kUdElX19hE30fe2H08xOE1b3P76O+K3Azlcb0meTHJ6VT3efpEdOMym3g18rqp+1Nn25F/SzyX5Y+B3xt1bVe1vHx9J8gXgjcCfMuJxm6v+kpwE3MrgD4bdnW2PdOymmMnbxkyO2ZdkMfByBt9f8/2WMzPafpK3MwjfX66q5ybrPV/fufxFN21/VfVUZ/ZTDJ6Pmlz3rVPW/cI4e+vYAFzaLYzh2B1OX++zPmbH++WmoW/7UYNneu5i8FwAwEZgLs9MdrRtzmTbL7je2X45Tj4HcCEw9E6H+eotyZLJyzRJTgXeAjw4huM20/5OAD7H4Nrs9inL5vLYzeRtY7r9XgTc2Y7TDmBDBnc/rQRWAV8eoZcj7i3JG4H/BLyzqg506kO/vnPY20z7O70z+07goTa9Ezi39bkEOJefPdOe995af69j8CTwlzq1cRy7w9kBXNLucloLPNv+MJr9MZuvZ+EX+gH8fQbX3Z4DngR2tvorgds64y4Avskg6T/Sqb+awQ/tBPAnwIlz2NsrgDuAvcDngVNafQ3wqc64FQz+Avi5KevfCdzH4BfcfwF+YZy9AX+37f8b7eOmcRy3I+jv14AfAV/vPN4wH8du2PcPg8tX72zTL2nHYaIdl1d31v1IW+9h4Px5+BmYrrfPt5+NyWO0Y7qv75j7+7fAA62Pu4DXddb99XZMJ4D3jru3Nv9vgCunrDevx47BH4yPt+/vfQyeS3o/8P62PAz+Udu32v7XdNad1THzbTkkSb2O98tNkqTDMCQkSb0MCUlSL0NCktTLkJAk9TIkJEm9DAlJUq//B0ZMZh/VGQ9uAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([item for sublist in list(native_cos_sims.values()) for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c451983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_rep(native_vectors, model_path):\n",
    "    \n",
    "    #import imp\n",
    "    #imp.reload(module)\n",
    "    \n",
    "    vectors_torch = dl.TorchVectors(list(native_vectors.items()))\n",
    "    val_loader = DataLoader(vectors_torch, batch_size=1, pin_memory=True, shuffle=False)\n",
    "\n",
    "    # Retrieve the architecture of the model\n",
    "    params = torch.load(model_path)\n",
    "    latent_size, input_size = params['state_dict']['net.0.weight'].shape\n",
    "    weights_encode = torch.nn.Parameter(params['state_dict']['net.0.weight'])\n",
    "    \n",
    "    # Initialize the encoding layer, apply weights\n",
    "    to_latent_nn = nn.Linear(input_size, latent_size, bias=False)\n",
    "    to_latent_nn.weight = weights_encode\n",
    "    to_latent_nn.eval()\n",
    "    to_latent_nn.cuda()\n",
    "    \n",
    "    output = dict()\n",
    "\n",
    "    for idx, batch in enumerate(val_loader):\n",
    "        \n",
    "        key, vals = batch[0][0], batch[1]\n",
    "        inputs = Variable(vals).cuda()\n",
    "        with torch.no_grad():\n",
    "            output[key] = to_latent_nn(inputs)\n",
    "    to_latent_nn.cpu()\n",
    "\n",
    "    latent_vectors = dict()\n",
    "\n",
    "    for key, vals in output.items():\n",
    "        latent_vectors[key] = vals.cpu().numpy()[0]\n",
    "    \n",
    "    return latent_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c67ab47",
   "metadata": {},
   "source": [
    "#### Now map to the latent space for a model before checking the improvement in alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88fc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = get_latent_rep(lincs_vectors, \"../trained_model_parameters/LeakyReLu/5.93e-06_counts150epoch_leakyReLu_960_1024_model_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5284062",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_vectors_latent = get_mean_vec_from_control(latent_vectors, pert_cell_vector_dict, cnt_condition = \"DMSO\", batch_cor = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce150def",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_cos_sims = get_group_cos_sims(mean_vectors_latent, meta_data, grp_id = 'pert_iname', ind_id = 'cell_id', mean = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(latent_cos_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([item for sublist in list(native_cos_sims.values()) for item in sublist], alpha = 0.5)\n",
    "plt.hist([item for sublist in list(latent_cos_sims.values()) for item in sublist], alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060276f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([item for sublist in list(native_cos_sims.values()) for item in sublist], [item for sublist in list(latent_cos_sims.values()) for item in sublist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b13c10",
   "metadata": {},
   "source": [
    "#### Do this in a loop to evaluate multiple architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee2697e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../trained_model_parameters/LeakyReLu/*.pth')\n",
    "\n",
    "eval_df = pd.DataFrame(columns = ['File', 'Non-linearity', 'Latent dimension', 'Loss (1e-6)', 'Abs. Alignment'])\n",
    "\n",
    "for f in files:\n",
    "    \n",
    "    latent_vectors = get_latent_rep(lincs_vectors, f)\n",
    "    \n",
    "    mean_vectors_latent = get_mean_vec_from_control(latent_vectors, pert_cell_vector_dict, cnt_condition = \"DMSO\", batch_cor = True)\n",
    "    \n",
    "    latent_cos_sims = get_group_cos_sims(mean_vectors_latent, meta_data, grp_id = 'pert_iname', ind_id = 'cell_id', mean = False)\n",
    "    \n",
    "    file = '_'.join((f.split('\\\\')[1].split('_')[1:5]))\n",
    "    nonLin = (f.split('\\\\')[1].split('_')[2])\n",
    "    latent_dim = float((f.split('\\\\')[1].split('_')[4]))\n",
    "    loss = float(f.split('\\\\')[1].split('_')[0]) * 1e6\n",
    "    \n",
    "    alignment = np.mean((np.abs([item for sublist in list(latent_cos_sims.values()) for item in sublist])))\n",
    "    \n",
    "    eval_df.loc[len(eval_df)] = [file, nonLin, latent_dim, loss, alignment]\n",
    "\n",
    "# Add row for native vectors\n",
    "eval_df.loc[len(eval_df)] = ['Native', 'N/A', 'N/A', 0, \n",
    "                             np.mean((np.abs([item for sublist in list(native_cos_sims.values()) for item in sublist])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47998bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Non-linearity</th>\n",
       "      <th>Latent dimension</th>\n",
       "      <th>Loss (1e-6)</th>\n",
       "      <th>Abs. Alignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>counts150epoch_5pat_leakyReLu_960</td>\n",
       "      <td>5pat</td>\n",
       "      <td>960.0</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.647778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>counts150epoch_leakyReLu_960_1200</td>\n",
       "      <td>leakyReLu</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.558592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>counts150epoch_leakyReLu_960_1300</td>\n",
       "      <td>leakyReLu</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.590915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>counts150epoch_leakyReLu_960_1400</td>\n",
       "      <td>leakyReLu</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.566082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>counts150epoch_leakyReLu_960_1100</td>\n",
       "      <td>leakyReLu</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.653682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>counts150epoch_leakyReLu_960_1000</td>\n",
       "      <td>leakyReLu</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.65</td>\n",
       "      <td>0.636925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>counts150epoch_leakyReLu_960_1024</td>\n",
       "      <td>leakyReLu</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>5.93</td>\n",
       "      <td>0.636925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>counts150epoch_leakyReLu_960_900</td>\n",
       "      <td>leakyReLu</td>\n",
       "      <td>900.0</td>\n",
       "      <td>62.73</td>\n",
       "      <td>0.623811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Native</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.297017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                File Non-linearity Latent dimension  \\\n",
       "0  counts150epoch_5pat_leakyReLu_960          5pat            960.0   \n",
       "1  counts150epoch_leakyReLu_960_1200     leakyReLu           1200.0   \n",
       "2  counts150epoch_leakyReLu_960_1300     leakyReLu           1300.0   \n",
       "3  counts150epoch_leakyReLu_960_1400     leakyReLu           1400.0   \n",
       "4  counts150epoch_leakyReLu_960_1100     leakyReLu           1100.0   \n",
       "5  counts150epoch_leakyReLu_960_1000     leakyReLu           1000.0   \n",
       "6  counts150epoch_leakyReLu_960_1024     leakyReLu           1024.0   \n",
       "7   counts150epoch_leakyReLu_960_900     leakyReLu            900.0   \n",
       "8                             Native           N/A              N/A   \n",
       "\n",
       "   Loss (1e-6)  Abs. Alignment  \n",
       "0        10.72        0.647778  \n",
       "1         1.15        0.558592  \n",
       "2         1.25        0.590915  \n",
       "3         1.28        0.566082  \n",
       "4         1.36        0.653682  \n",
       "5         5.65        0.636925  \n",
       "6         5.93        0.636925  \n",
       "7        62.73        0.623811  \n",
       "8         0.00        0.297017  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7ad30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv('Eval. Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbfb63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
